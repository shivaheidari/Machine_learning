{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kqbPdQItZx24"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class winedataset(Dataset):\n",
        "  def __init__(self,transform=None):\n",
        "    xy=np.loadtxt(\"wine.csv\",dtype=np.float32, skiprows=1, delimiter=\",\")\n",
        "    self.n_samples = xy.shape[0]\n",
        "\n",
        "    self.x = xy[:,1:]\n",
        "    self.y = xy[:,[0]]\n",
        "\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "\n",
        "    sample = self.x[index], self.y[index]\n",
        "\n",
        "    if self.transform:\n",
        "\n",
        "      sample=self.transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples\n",
        "\n",
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "class MulTransform:\n",
        "\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, targets"
      ],
      "metadata": {
        "id": "37E6uMRbaC3h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = winedataset(transform=ToTensor())\n",
        "firstdata = dataset[0]\n",
        "features, labels= firstdata\n",
        "print(features)\n",
        "print(type(features), type(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAp5MKUvwhhF",
        "outputId": "9aacc26c-63fd-42a2-e662-8bc005d4a4d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)])"
      ],
      "metadata": {
        "id": "aNEZzJcr3mPV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = winedataset(transform = composed)\n",
        "firstdata = dataset[0]\n",
        "features, labels= firstdata\n",
        "print(type(features), type(labels))\n",
        "\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTx9vF-p35X1",
        "outputId": "fe9b0078-5aab-4028-ead3-b92f9930f69f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n",
            "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
            "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
            "        2.1300e+03])\n"
          ]
        }
      ]
    }
  ]
}