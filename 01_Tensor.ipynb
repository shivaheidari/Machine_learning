{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Tensor's concept</h1>\n",
        "Deeplearning as a transformer from one representation to another.</br>\n",
        "Tensor is a data structure for Pytorch. Tensors are the generalizaion of vectors and matrices to an arbitary numbers of dimensions.</br>\n",
        "Compared to the Numpy arrays, Pytorch have a few superpowers such as ability to perform very fast operations on graphical processing untis, distribute operations on multople devices or machines."
      ],
      "metadata": {
        "id": "cWnBi4sf1qBa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "O-QcEJaSzYW7"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creates a one-dimensional tesnor of size 3 filled with 1s\n",
        "a=torch.ones(3)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCcrFjOksLyT",
        "outputId": "9db068ef-7bf4-464d-d5da-20346e293449"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RRkHVvh8sXWI",
        "outputId": "35230315-9235-471e-901b-8e6363594405"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float(a[1])\n",
        "a[2]=2\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AFQmxqSscME",
        "outputId": "71dc03fe-fd03-4d03-f502-4879066a0ee1"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lists and tuples in python are collections of objects. It means that each element might be allocated in diffrenent part of memory.In contrast, Tensor and Arrays's elements are sotred in a continues memeory."
      ],
      "metadata": {
        "id": "KYVd9IOOudT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points=torch.tensor([[4,1],[5,3]])\n"
      ],
      "metadata": {
        "id": "0zSv9NHWsr3U"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "points.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHzpkwOg3EkU",
        "outputId": "c3662e5d-8c64-4fb2-fd4a-f2ea50d9fac2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "points[0,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBYzR89G3ITY",
        "outputId": "318f06d0-a359-4f62-c94b-668741af52e7"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "points[1:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5w5TT833WDj",
        "outputId": "df8e1675-7b35-4111-9c42-ce595cfe6916"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Named Tensors</h3>\n",
        "ie: Converting colored image to gray scale. RGB channnels are located in index of [-3]"
      ],
      "metadata": {
        "id": "G6uP0NYQ7CvV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_t=torch.randn(3,5,5)#shape[channels, rows, columns]\n",
        "weights=torch.tensor([0.2126, 0.7152,0.0722])"
      ],
      "metadata": {
        "id": "nFhZB4SR4owD"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_t=torch.randn(2,3,5,5)#shape[batch, chanels, rows, columns]"
      ],
      "metadata": {
        "id": "4BifQ4Df7eFN"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_gray_naive=img_t.mean(-3)\n",
        "batch_img_gray_naive=batch_t.mean(-3)\n",
        "img_gray_naive\n",
        "batch_img_gray_naive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlVroVd-84rj",
        "outputId": "e0052cf4-22ca-4b80-91b4-dc15af7059a3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.2554,  0.1765, -0.5528,  0.5690,  0.9700],\n",
              "         [ 0.2219, -0.5857, -0.3615, -0.7718, -0.2711],\n",
              "         [ 1.1073, -0.6333, -0.6223,  0.3477, -0.0507],\n",
              "         [ 1.1219,  0.4698, -0.6062, -1.4743, -1.0756],\n",
              "         [-1.0320,  0.7256, -0.4783,  0.6332, -0.4183]],\n",
              "\n",
              "        [[-0.1246,  0.7163,  0.1684,  0.3687, -0.4065],\n",
              "         [-0.6492, -1.0191,  0.3327,  1.1169,  0.4182],\n",
              "         [ 0.7979, -0.5157,  0.5973,  0.0659,  1.2550],\n",
              "         [-0.4614, -0.7576, -0.6590,  0.6857, -0.1096],\n",
              "         [-0.6544, -0.1189, -0.1236,  0.7037, -0.3521]]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As pytorch use broadcasting for operations, it is highly recommended to use named indexes for tracking."
      ],
      "metadata": {
        "id": "UhCK5eCm9378"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NCHW=[\"N\", \"C\", \"H\", \"W\"]\n",
        "images=torch.randn(3,2,5,5 , names=NCHW)\n",
        "res=images.sum(\"C\")\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAM7ne4r9ziX",
        "outputId": "e910c5ad-502c-480e-d0a3-05ee203e91ae"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.3982, -1.0144, -0.6110, -0.5449, -0.2121],\n",
              "         [-1.0982, -1.4431, -1.5409,  1.6746, -3.9580],\n",
              "         [-0.9680, -0.9913,  2.1736, -1.8231, -0.2546],\n",
              "         [-1.4500, -0.7750,  0.9510, -2.2770,  0.7449],\n",
              "         [-0.9007,  3.0159, -0.4198, -0.8948, -0.0720]],\n",
              "\n",
              "        [[ 1.1935,  1.4958, -0.6159, -0.1874, -1.2557],\n",
              "         [ 1.3461,  0.2959,  0.6701, -4.3779,  1.3770],\n",
              "         [ 2.0587,  0.0471, -0.7523, -0.2258, -1.0636],\n",
              "         [ 0.3870, -0.3050,  0.6634,  1.1794, -1.3126],\n",
              "         [-2.7136, -0.5562, -1.2149, -2.0520, -2.1819]],\n",
              "\n",
              "        [[-0.2609,  0.2496,  0.2268, -0.2920, -1.4654],\n",
              "         [ 0.4176, -2.5598,  1.7939,  2.4022,  2.6392],\n",
              "         [ 0.7778,  3.0709,  0.9999,  0.6221, -0.1867],\n",
              "         [ 1.4476, -0.9277, -0.6893,  2.3274, -0.7087],\n",
              "         [-2.5611, -0.5807, -1.3334, -0.6393, -1.1127]]],\n",
              "       names=('N', 'H', 'W'))"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Tensor element types</h3>\n",
        "Numbers in python are objects. It makes prblem when we are dealing with allocating millions of numbers. It is not efficient.</br>\n",
        "The python interpreter is slow compared to the optimized compled coed.</br>\n",
        "For these reasons, data science libraries rely on NumPy or introduce dedicated data\n",
        "structures like PyTorch tensors, which provide efficient low-level implementations of\n",
        "numerical data structures and related operations on them, wrapped in a convenient\n",
        "high-level API\n"
      ],
      "metadata": {
        "id": "BbrG3tFilZDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "double_points=torch.ones(10,2,dtype=torch.double)\n",
        "short_points=torch.tensor([[1,2],[3,4]],dtype=torch.short)"
      ],
      "metadata": {
        "id": "-MkXu8dQlYDS"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " short_points.dtype"
      ],
      "metadata": {
        "id": "HfAj6_P0TBOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4737e00-09a4-4c79-fd66-7773d212922b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int16"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#casting the datatype\n",
        "double_points=torch.zeros(10,2).double()"
      ],
      "metadata": {
        "id": "U-ZnyUSFpFHT"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under the hood, to checks whether the conversion is necessary and, if so, does it."
      ],
      "metadata": {
        "id": "-2ipjPZnsnte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#the more convinient way\n",
        "double_points=torch.zeros(10,2).to(torch.double)"
      ],
      "metadata": {
        "id": "PjWw-zUcry3T"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>The tensor API</h3>"
      ],
      "metadata": {
        "id": "4bqxAp_YtDLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.ones(3,2)\n",
        "#input 1 the tensor \n",
        "#input 2 the first dimension to the be transposed\n",
        "#input 3 the second dimension to be trapsposed\n",
        "a_t=torch.transpose(a,0,1)"
      ],
      "metadata": {
        "id": "Dy7O6_njtCkD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#another way\n",
        "a.transpose(0,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nf4HftfvsqRc",
        "outputId": "ded4018d-2ffd-43e4-e164-c2c05896177e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transposing in higher dimension"
      ],
      "metadata": {
        "id": "CyW2ohw1FWlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "some_t=torch.ones(3,4,5)\n",
        "transpose_t=some_t.transpose(0,2)\n",
        "some_t.shape#(3,4,5)\n",
        "transpose_t.shape#(5,4,3)\n",
        "some_t.stride()#(20,5,1)\n",
        "transpose_t.stride()#(1,5,20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-RMV5PWFWHI",
        "outputId": "9a7858f9-d5fa-4fb6-c22a-d5dd7d190061"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 5, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "points=torch.tensor([[1,2],[3,4]])\n",
        "points_t=points.t()\n",
        "#t is a function for transforming for two dimensional tensors"
      ],
      "metadata": {
        "id": "S1nhk9hYGiCF"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "indexing into storage"
      ],
      "metadata": {
        "id": "9f9c0-yTxLtt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points=torch.tensor([[4 , 1],[5,3],[2,1]])\n",
        "print(points.storage())\n",
        "points_storage=points.storage()\n",
        "points_storage[0]\n",
        "points.storage()[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBZUUoXqu3rd",
        "outputId": "254e5725-d9e5-4977-e94d-3c41e07e3d6c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 4\n",
            " 1\n",
            " 5\n",
            " 3\n",
            " 2\n",
            " 1\n",
            "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 6]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Inplace modifying</h3>"
      ],
      "metadata": {
        "id": "SycB_cWL0GWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a=torch.ones(3,2)\n",
        "a.zero_()\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZZelEc8xdZE",
        "outputId": "94582d6e-3b2b-4488-c9cb-7a7d6b414598"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Tensor metadata: Size, Offset Stride</h3>\n",
        "sizes: shape(rows and columns)</br>\n",
        "offset: the index in the storage corresponding to the first element in the tensor</br>\n",
        "stride: the numebr of elements in the storage that need to be skipped over to obtain the next element along each dimension.\n"
      ],
      "metadata": {
        "id": "gTywV3bB25lW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points=torch.tensor([[4,1],[5,3],[2,1]])\n",
        "second_point=points[1]\n",
        "second_point#[5,3]\n",
        "second_point.storage_offset()#2\n",
        "second_point.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Y8VOil25Fu",
        "outputId": "ff33c003-4880-4d20-f6d5-941d7d68b851"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing an element i, j in a 2D tensor results in accessing the storage_offset +\n",
        "stride[0] * i + stride[1] * j element in the storage."
      ],
      "metadata": {
        "id": "ksImyvhh8gRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_point[0]=10\n",
        "points"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhB4lM4M1Et8",
        "outputId": "1295338a-b860-48b3-e732-6905a079e8cd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  1],\n",
              "        [10,  3],\n",
              "        [ 2,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clone\n",
        "third_point=points[2].clone()\n",
        "third_point[0]=10\n",
        "points\n",
        "#did not change due to working with the clone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSC0cR_a-G0O",
        "outputId": "4cda642f-6907-4b9c-c4c1-b5fabdfd96aa"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  1],\n",
              "        [10,  3],\n",
              "        [ 2,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Contiguous tensors</h3>\n",
        "Some tensor operations in PyTorch only work on contiguous tensors, such as view."
      ],
      "metadata": {
        "id": "qOAZUm06Hoi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "points.is_contiguous()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyd87ttS-l_t",
        "outputId": "9e259521-2001-4d7c-8002-f810246dd5cb"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "points_t.is_contiguous()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MaVq8OvICNk",
        "outputId": "c09c4ad9-1097-4cbe-a437-14a9bff208bd"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can obtain a new contiguous tensor from a non-contiguous one using the contiguous method. When a tensor is transposed, the stride is changed instead of changeing the storage memory. For changing the memory and the way of storing elements of tensors, we can make the storage continueus by contiguous() function."
      ],
      "metadata": {
        "id": "qv_9P4EFIOuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Moving tensors to the GPU"
      ],
      "metadata": {
        "id": "6now-aizPkbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#points_gpu=points.to(device=\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "ww8_p_PUIQ4u",
        "outputId": "bccf339a-b939-4a6c-c905-435e99f946d8"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-f4e27333d3ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpoints_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    }
  ]
}